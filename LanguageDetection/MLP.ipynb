{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7HgJmYrAXrH"
      },
      "source": [
        "## PJ : Faris Fadhilah / 13518026 ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq_x2_6qd3wl"
      },
      "source": [
        "### Import Libraries ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26wNLNBmZwMl"
      },
      "source": [
        "# Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import tensorflow as tf # create neural networks\n",
        "from tensorflow.keras import Sequential # create squential NN model\n",
        "from tensorflow.keras.layers import Dense # implements the operation: output = activation(dot(input, kernel) + bias)\n",
        "from tensorflow.keras.models import load_model # load saved model\n",
        "from tensorflow.keras.utils import plot_model # plot model architecture\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98Aw2-jpeG9m"
      },
      "source": [
        "### Import Dataset ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFfJaDWdYyUT"
      },
      "source": [
        "# Import Dataset\n",
        "data = pd.read_csv(\"dataset.csv\")\n",
        "data = data.iloc[:6000,:]\n",
        "# Separate Features\n",
        "X = data[\"Text\"]\n",
        "y = data[\"Language\"]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "910Lg8UweQkC"
      },
      "source": [
        "### Label Encoding ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82zxnd77deJU"
      },
      "source": [
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMiHBsGqfuSH"
      },
      "source": [
        "### Text Preprocessing ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZ92d2e5eoBe",
        "outputId": "e6073054-1542-43f6-e9b7-c78ad5c19fa6"
      },
      "source": [
        "# creating a list for appending the preprocessed text\n",
        "data_list = []\n",
        "# iterating through all the text\n",
        "for text in X:\n",
        "       # removing the symbols and numbers\n",
        "        text = re.sub(r'[!@#$(),n\"%^*?:;~`0-9]', ' ', text)\n",
        "        text = re.sub(r'[[]]', ' ', text)\n",
        "        # converting the text to lower case\n",
        "        text = text.lower()\n",
        "        # appending to data_list\n",
        "        data_list.append(text)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: FutureWarning: Possible nested set at position 1\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2cdLYjqgBRK"
      },
      "source": [
        "### Bag of Words ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EgmKOwHeurl"
      },
      "source": [
        "cv = CountVectorizer()\n",
        "X = cv.fit_transform(data_list).toarray()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywxhWhCsgGvf"
      },
      "source": [
        "### Train Test Splitting ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB0_u6PugAGt"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STw0bKR-gNTc"
      },
      "source": [
        "### Define Model Multi Layer Perceptron (MLP) ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHA9gdole4Ad"
      },
      "source": [
        "# input size hyperparameter\n",
        "INPUT_SIZE = x_train.shape[1]\n",
        "INPUT_SIZE\n",
        "# outputsize hyperparatmeter\n",
        "OUTPUT_SIZE = len(data['Language'].unique())\n",
        "OUTPUT_SIZE\n",
        "# epochs and batch_size hyperparameters\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 128\n",
        "# creating the MLP model\n",
        "model = Sequential([Dense(100, activation='relu', kernel_initializer='he_normal', input_shape=(INPUT_SIZE,)),Dense(80, activation='relu', kernel_initializer='he_normal'), Dense(50, activation='relu', kernel_initializer='he_normal'),Dense(OUTPUT_SIZE, activation='softmax')])\n",
        "# compiling the MLP model\n",
        "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8YN6B75gh95"
      },
      "source": [
        "### Train Model ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ik0r84HfFVw",
        "outputId": "de73796a-a0e6-427e-bb5e-047a05a85909"
      },
      "source": [
        "# fitting the MLP model\n",
        "start_time = time.time()\n",
        "hist = model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=0.3, verbose=2)\n",
        "print(\"Train Time Execution: %.3f seconds\" % (time.time() - start_time))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "27/27 - 8s - loss: 2.2964 - accuracy: 0.5643 - val_loss: 1.2165 - val_accuracy: 0.8813 - 8s/epoch - 286ms/step\n",
            "Epoch 2/30\n",
            "27/27 - 6s - loss: 0.5973 - accuracy: 0.9625 - val_loss: 0.4316 - val_accuracy: 0.9486 - 6s/epoch - 236ms/step\n",
            "Epoch 3/30\n",
            "27/27 - 6s - loss: 0.1014 - accuracy: 0.9985 - val_loss: 0.2994 - val_accuracy: 0.9507 - 6s/epoch - 236ms/step\n",
            "Epoch 4/30\n",
            "27/27 - 6s - loss: 0.0149 - accuracy: 0.9997 - val_loss: 0.2691 - val_accuracy: 0.9542 - 6s/epoch - 235ms/step\n",
            "Epoch 5/30\n",
            "27/27 - 6s - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 0.9535 - 6s/epoch - 237ms/step\n",
            "Epoch 6/30\n",
            "27/27 - 6s - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.2605 - val_accuracy: 0.9542 - 6s/epoch - 232ms/step\n",
            "Epoch 7/30\n",
            "27/27 - 6s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2577 - val_accuracy: 0.9528 - 6s/epoch - 235ms/step\n",
            "Epoch 8/30\n",
            "27/27 - 6s - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.2550 - val_accuracy: 0.9535 - 6s/epoch - 233ms/step\n",
            "Epoch 9/30\n",
            "27/27 - 6s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.2530 - val_accuracy: 0.9542 - 6s/epoch - 233ms/step\n",
            "Epoch 10/30\n",
            "27/27 - 6s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2518 - val_accuracy: 0.9528 - 6s/epoch - 234ms/step\n",
            "Epoch 11/30\n",
            "27/27 - 6s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.2502 - val_accuracy: 0.9535 - 6s/epoch - 234ms/step\n",
            "Epoch 12/30\n",
            "27/27 - 6s - loss: 8.6442e-04 - accuracy: 1.0000 - val_loss: 0.2495 - val_accuracy: 0.9535 - 6s/epoch - 236ms/step\n",
            "Epoch 13/30\n",
            "27/27 - 6s - loss: 7.4394e-04 - accuracy: 1.0000 - val_loss: 0.2485 - val_accuracy: 0.9542 - 6s/epoch - 233ms/step\n",
            "Epoch 14/30\n",
            "27/27 - 6s - loss: 6.4562e-04 - accuracy: 1.0000 - val_loss: 0.2475 - val_accuracy: 0.9549 - 6s/epoch - 233ms/step\n",
            "Epoch 15/30\n",
            "27/27 - 6s - loss: 5.6631e-04 - accuracy: 1.0000 - val_loss: 0.2467 - val_accuracy: 0.9549 - 6s/epoch - 236ms/step\n",
            "Epoch 16/30\n",
            "27/27 - 6s - loss: 5.0176e-04 - accuracy: 1.0000 - val_loss: 0.2458 - val_accuracy: 0.9535 - 6s/epoch - 234ms/step\n",
            "Epoch 17/30\n",
            "27/27 - 6s - loss: 4.4722e-04 - accuracy: 1.0000 - val_loss: 0.2453 - val_accuracy: 0.9549 - 6s/epoch - 232ms/step\n",
            "Epoch 18/30\n",
            "27/27 - 6s - loss: 4.0181e-04 - accuracy: 1.0000 - val_loss: 0.2448 - val_accuracy: 0.9549 - 6s/epoch - 233ms/step\n",
            "Epoch 19/30\n",
            "27/27 - 6s - loss: 3.6405e-04 - accuracy: 1.0000 - val_loss: 0.2444 - val_accuracy: 0.9556 - 6s/epoch - 234ms/step\n",
            "Epoch 20/30\n",
            "27/27 - 6s - loss: 3.2997e-04 - accuracy: 1.0000 - val_loss: 0.2437 - val_accuracy: 0.9556 - 6s/epoch - 234ms/step\n",
            "Epoch 21/30\n",
            "27/27 - 6s - loss: 3.0050e-04 - accuracy: 1.0000 - val_loss: 0.2435 - val_accuracy: 0.9542 - 6s/epoch - 235ms/step\n",
            "Epoch 22/30\n",
            "27/27 - 6s - loss: 2.7526e-04 - accuracy: 1.0000 - val_loss: 0.2428 - val_accuracy: 0.9556 - 6s/epoch - 237ms/step\n",
            "Epoch 23/30\n",
            "27/27 - 6s - loss: 2.5292e-04 - accuracy: 1.0000 - val_loss: 0.2426 - val_accuracy: 0.9528 - 6s/epoch - 237ms/step\n",
            "Epoch 24/30\n",
            "27/27 - 6s - loss: 2.3353e-04 - accuracy: 1.0000 - val_loss: 0.2421 - val_accuracy: 0.9535 - 6s/epoch - 234ms/step\n",
            "Epoch 25/30\n",
            "27/27 - 6s - loss: 2.1556e-04 - accuracy: 1.0000 - val_loss: 0.2419 - val_accuracy: 0.9535 - 6s/epoch - 234ms/step\n",
            "Epoch 26/30\n",
            "27/27 - 6s - loss: 2.0001e-04 - accuracy: 1.0000 - val_loss: 0.2415 - val_accuracy: 0.9535 - 6s/epoch - 235ms/step\n",
            "Epoch 27/30\n",
            "27/27 - 6s - loss: 1.8616e-04 - accuracy: 1.0000 - val_loss: 0.2413 - val_accuracy: 0.9535 - 6s/epoch - 234ms/step\n",
            "Epoch 28/30\n",
            "27/27 - 6s - loss: 1.7357e-04 - accuracy: 1.0000 - val_loss: 0.2409 - val_accuracy: 0.9535 - 6s/epoch - 234ms/step\n",
            "Epoch 29/30\n",
            "27/27 - 6s - loss: 1.6230e-04 - accuracy: 1.0000 - val_loss: 0.2406 - val_accuracy: 0.9535 - 6s/epoch - 235ms/step\n",
            "Epoch 30/30\n",
            "27/27 - 6s - loss: 1.5206e-04 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9535 - 6s/epoch - 235ms/step\n",
            "Train Time Execution: 202.740 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9TjZejUg8ja"
      },
      "source": [
        "### Evaluate Model ####"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwhpLSNbffch",
        "outputId": "232f9e7a-9c3a-449a-a712-6387bdc3a98a"
      },
      "source": [
        "# summary of the MLP model\n",
        "model.summary()\n",
        "# architetcure of the MLP model\n",
        "plot_model(model, show_shapes=True)\n",
        "# evaluating the loss and accuracy of the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 100)               10233800  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 80)                8080      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 50)                4050      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 22)                1122      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,247,052\n",
            "Trainable params: 10,247,052\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "38/38 - 1s - loss: 0.2425 - accuracy: 0.9583 - 1s/epoch - 31ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oEPJfhZhMrL"
      },
      "source": [
        "### Save Model ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxZaWIHXfiUA"
      },
      "source": [
        "# saving the model\n",
        "model.save('language_detection_model2.h5')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJDZrxODssNY"
      },
      "source": [
        "### Function Predict Sentence ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWNQ2wANhxAZ"
      },
      "source": [
        "# function for predicting language\n",
        "def predict(text):\n",
        "    x = cv.transform([text])\n",
        "    lang = model.predict(x)\n",
        "    lang = np.argmax(lang)\n",
        "    print(\"This text is in\",le.inverse_transform([lang])[0])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQpY-EXvhRnY"
      },
      "source": [
        "### Load Model & Predict ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqRDaBQTfrB4",
        "outputId": "5ce9dad0-1f7e-4547-e101-9ab8f1f78973"
      },
      "source": [
        "start_time = time.time()\n",
        "# loading the model\n",
        "model = load_model('language_detection_model2.h5')\n",
        "# predict language\n",
        "predict(\"We use a dataset that contains 22 selective languages from the original dataset which includes the following Languages\")\n",
        "print(\"Predict Time Execution: %.3f seconds\" % (time.time() - start_time))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This text is in English\n",
            "Predict Time Execution: 0.599 seconds\n"
          ]
        }
      ]
    }
  ]
}